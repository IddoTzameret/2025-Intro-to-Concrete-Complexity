%%%%%%%%%%%%%%%%%%%%% chapter2.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  Monotone Circuits Lower bounds 
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%
%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}





\chapter{Monotone Circuit Lower Bounds}
\label{sec:Razborov} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head


% Always give a unique label
% and use \ref{<label>} for cross-references
% and \cite{<label>} for bibliographic references
% use \sectionmark{}
% to alter or adjust the section heading in the running head

We have  seen that proving that SAT is not in \Ppoly, i.e., cannot  be solved by polynomial-size circuits, implies that $\P \neq \NP$.
Due to the notorious difficulty of this and related questions, we are also interested in proving \emph{weaker} lower bounds, namely, lower bounds against \emph{restricted} classes of circuits. Although this does not settle the main lower bound questions, it is still considered an important step towards the bigger questions, at least from the methodological perspective. 
Here, we study such a restricted circuit class and prove a lower bound against it: Boolean circuits without negation gates, which are also called \emph{ monotone circuits}.

\para{Monotone Circuits}

\begin{definition}[Monotone circuit]
A \emph{monotone circuit} is a Boolean circuit that contains fan-in two gates AND and OR, but has \emph{no} NOT gates.
\end{definition}

Note in particular that monotone circuits can compute only monotone functions: a Boolean function is said to be monotone if \emph{increasing the number of ones} in the input cannot flip the value of the function from 1 to 0. More precisely, for $\bar{x}, \bar{y} \in\{0,1\}^n$, write $\bar{x} \geq \bar{y}$ iff $ \forall i \in [n], x_i \geq y_i$, where $[n]$ denotes $\{1,\dots,n\}$. (Here, $x_i\ge y_i$ for Boolean $x_i,y_i$ means simply that $1\ge 0$ and $0\ge 0$, $1\ge 1$, while $0\not\ge 1$.)

\begin{definition}[Monotone function]
A Boolean function $f:\{0,1\}^n \rightarrow\{0,1\}$ is said to be  \emph{monotone} if $\forall \bar{x} \geq \bar{y}, f(\bar{x}) \geq f(y)$.
\end{definition}

\section{The CLIQUE Problem}
Many \NP-complete problems are monotone. One example of an \NP-complete decision problem is  CLIQUE we describe now. 
Given an undirected graph $G=(V, E)$ with $n$ nodes, a \emph{$k$-clique} in $G$ is a set $U\subseteq V$ of size $k$, such that  every pair of nodes $u_1, u_2 \in U$ is connected by an edge (in $E$), and in symbols:
$$
 \forall u_1 \in U~\forall u_2 \in U~ ( u_1 \neq u_2\Rightarrow (u_1, u_2)\in E).
$$


Recall that a computational decision problem is a language over a finite alphabet (usually \bits). Here, our language consists of all the strings that encode (in some natural way) an accepted graph, i.e., a graph with $n$ nodes that contains a $k$-clique.
The natural way to encode a graph in our case is this: a graph  $G=(V, E) $ with $n$ nodes, is encoded by $\binom{n}{2}$ input variables  $x_{ij}$, where the semantic of the encoding is: $x_{i j}=1$ iff $(i, j) \in E$. In other words, if the input variable $x_{ij}=1$,   our input graph contains the edge $(i,j)$, and otherwise it does not. 

We are interested in CLIQUE$(k, n)$ for a \emph{fixed} $k$, considered as the following Boolean function: 
\begin{svgraybox}
The computational problem \textbf{CLIQUE$(k, n)$}: 

\textit{Input}: Undirected graph $G=(V,E)$ with $n$ nodes encoded as a length $n\choose 2$ binary string (each bit represents an  edge  $x_{ij}$, $i<j\in[n]$), and a number $k$ (given in unary, i.e., $1^k$).

\textit{Accept}: if the graph $G$ contains a $k$-clique. 

\textit{Reject}: otherwise.
\end{svgraybox}


 
 
It is known that CLIQUE$(k,n)$ is NP-complete (see standard complexity textbooks; e.g., Papadimitriou 1994).
Note that $\operatorname{CLIQUE}(k, n)$ is a monotone function: if we add 1's to the input, we only \emph{increase} the chance it has a $k$-clique. Since CLIQUE$(n, k)$ is a monotone (Boolean)
function we can compute it by a monotone Boolean circuit. But the question remains whether we can compute CLIQUE$(n, k)$ with small monotone circuit. 

\begin{trailer}{Example of a monotone circuit computing CLIQUE$(n, k)$}
Consider  all $\binom{n}{k} ~~ k$-sub-graphs in $G$, and check if at least one of those is a clique:

\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{images/k-clique-simple-circuit.png}
    \label{fig:clique-naive}
    \caption{Naive way to compute CLIQUE}
\end{figure}

$S_1, S_2, \ldots, S_{\binom{n}{k}}$ are the $\binom{n}{k}$ subgraphs in $G$ each of size $k$.
Size of this circuit: $O\left(k^2 \cdot\binom{n}{k}\right)$.
\end{trailer}

\subsection{Crude Circuits for CLIQUE}

A  circuit for computing $\operatorname{CLIQUE}  (n, k),$ consisting of an OR gate $\bigvee$ of many  $S_i$'s, each of size $k$ and where each $S_i$ is an AND of the edge variables in $S_i$, as in the example above, is called a \textit{crude-circuit} for CLIQUE($n, k)$. More formally, we have the following. 

% *Do not* use the \begin{tcolorbox}[float=..] %option, unless you wish it to float around; namely %not appear sequentially as you put in in the %text. 

\begin{tcolorbox}[colframe=white, colback=red!5, boxrule=0mm, sharp corners]
\textbf{Crude-circuits $CC\left(X_1, \ldots, X_m\right)$ for CLIQUE}.
Let $V$ be a set of nodes and let $X_1,\dots,X_n\in V$ be a collection of subsets of nodes. The \emph{crude-circuit} $CC\left(X_1, \ldots, X_m\right)$ is defined to be 
$\bigvee_{r=1}^m\bigwedge_{i<j \in X_r} x_{ij}$.
Note that the $X_i$'s may have different sizes (and specifically their sizes may be different from $k$).
\end{tcolorbox}
 
Note that $CC\left(X_1, \ldots, X_m\right)(\alpha)=1$, for $\alpha\in\bits^{n\choose 2}$, precisely when in the graph $G$ over the nodes $V$ described by the assignment $\alpha$, at least one of the $X_i$ subgraphs is a clique. 

We shall also use the abbreviated notation $CC(\mathcal X)$ for $CC(X_1,\dots,X_m)$ when $\mathcal X = \{X_1,\dots,X_m\}$.

% We denote by $CC\left(S_1, \ldots, S_{\binom{n}{k}}\right)$ the crude circuit computing the $\bigvee$ of all subgraphs $S_1, \ldots, S_{n\choose k }$.

\begin{trailer}{Example of simple useful asymptotic computations}
%\begin{note} 
Note that when $k\in(\Omega(\log n),O(n-\log n))$, $CC\left(S_1, \ldots, S_{n\choose k}\right)$, where $S_1,\dots,S_{n\choose k}$ are all possible subsets of size $k$ from the set of $n$ nodes $V$, is of \emph{super-polynomial size}, because $ n\choose k$ is super polynomial for $k$ in this range. For the sake of getting used to asymptotic estimates such as these, it is helpful to go over the computations in more detail, as follows.

We shall estimate the asymptotic behaviour of $\binom{n}{\log n} $, showing it is superpolynomial, namely, $\binom{n}{\log n} =
n^{\Omega(\log n)}$. Stirling's approximation for factorials helps simplify the expressions: 
\begin{tcolorbox}[colframe=white, colback=gray!5, boxrule=0mm, sharp corners]
\textbf{Stirling's Approximation}:
$n!\sim \sqrt{2 \pi n}\left(\frac{n}{e}\right)^n$, where $e$ is the natural logarithm.
\end{tcolorbox}

By definition, we have $\binom{n}{\log n} =\frac{n!}{\log n!(n-\log n)!}$. Hence, using Stirling's approximation to substitute the factorials we get:
\[
 \binom{n}{\log(n)} \sim \frac{\sqrt{2 \pi n} \left(\frac{n}{e}\right)^n}{\sqrt{2 \pi \log(n)} \left(\frac{\log(n)}{e}\right)^{\log(n)} \sqrt{2 \pi (n - \log(n))} \left(\frac{n - \log(n)}{e}\right)^{n - \log(n)}}.
\]
 
Simplifying, we combine the square root terms:
   \[
   \frac{\sqrt{2 \pi n}}{\sqrt{2 \pi \log(n)} \sqrt{2 \pi (n - \log(n))}} \sim \frac{1}{\sqrt{2 \pi \log(n)}}.
   \]
Simplify the exponentials:    the \(\left(\frac{n}{e}\right)^n\) term dominates the numerator, and dividing by \(\left(\frac{\log(n)}{e}\right)^{\log(n)}\) and \(\left(\frac{n - \log(n)}{e}\right)^{n - \log(n)}\) leads to:

   \[
   \left(\frac{n}{n - \log(n)}\right)^{n - \log(n)} \cdot \left(\frac{n}{\log(n)}\right)^{\log(n)}.
   \]

For large \(n\), \(n - \log(n) \sim n\), namely, $n-\log (n) =\Omega(n)$, so:
 $
   \left(\frac{n}{n - \log(n)}\right)^{n - \log(n)} \sim 1.
 $
Hence, the dominant term becomes $\left(\frac{n}{\log(n)}\right)^{\log(n)}.$
Thus 
\[
\binom{n}{\log(n)} \sim \frac{1}{\sqrt{2 \pi \log(n)}} 
\cdot \left(\frac{n}{\log(n)}\right)^{\log(n)}
\ge  \left(\frac{n}{\log(n)}\right)^{c\log(n)}, 
\]
for some constant $c$, and all sufficiently large $n$'s.
% This is the same as writing
%\[
%\binom{n}{\log(n)} 
%=  \left(\frac{n}{\log(n)}\right)^{\Omega(\log(n))}. 
%\]
%
Using the fact that $2^{\log(\log n)}=\log n$,  we get:
\begin{align*}
\binom{n}{\log n} & \ge 2^{c\cd\log n\cd(\log n-\log(\log n))}\\
&   = 
2^{c\cd\log n\cd\log n-c\cd\log n \cd\log(\log n))}\\
&   = 
2^{c\cd\log^2 n-o(\log ^2n)}\\
&   =
2^{\Omega(\log^2(n))} = n^{\Omega(\log n)}.
\end{align*}

\end{trailer}
% 
% To asymptotically estimate \(\binom{n}{\log(n)}\), we can use the binomial coefficient formula and apply approximations for large \(n\). The binomial coefficient is defined as:
% 
% \[
% \binom{n}{k} = \frac{n!}{k!(n-k)!}.
% \]
% 
% Here, \(k = \log(n)\), where we assume the logarithm is base 2 unless specified otherwise. For large \(n\), this becomes:
% 
% \[
% \binom{n}{\log(n)} = \frac{n!}{(\log(n))!(n - \log(n))!}.
% \]
% 
% ### Using Stirling's Approximation
% Stirling's approximation for factorials (\(n! \sim \sqrt{2 \pi n} \left(\frac{n}{e}\right)^n\)) helps simplify the expressions. Applying this:
% 
% 1. For \(n!\):
%    \[
%    n! \sim \sqrt{2 \pi n} \left(\frac{n}{e}\right)^n.
%    \]
% 
% 2. For \((\log(n))!\):
%    \[
%    (\log(n))! \sim \sqrt{2 \pi \log(n)} \left(\frac{\log(n)}{e}\right)^{\log(n)}.
%    \]
% 
% 3. For \((n - \log(n))!\):
%    Since \(n - \log(n) \sim n\) for large \(n\), we approximate:
%    \[
%    (n - \log(n))! \sim \sqrt{2 \pi (n - \log(n))} \left(\frac{n - \log(n)}{e}\right)^{n - \log(n)}.
%    \]
% 
% ### Substituting
% Now substitute these approximations into the binomial coefficient:
% 
% \[
% \binom{n}{\log(n)} \sim \frac{\sqrt{2 \pi n} \left(\frac{n}{e}\right)^n}{\sqrt{2 \pi \log(n)} \left(\frac{\log(n)}{e}\right)^{\log(n)} \sqrt{2 \pi (n - \log(n))} \left(\frac{n - \log(n)}{e}\right)^{n - \log(n)}}.
% \]
% 
% ### Simplifying
% 1. Combine the square root terms:
%    \[
%    \frac{\sqrt{2 \pi n}}{\sqrt{2 \pi \log(n)} \sqrt{2 \pi (n - \log(n))}} \sim \frac{1}{\sqrt{2 \pi \log(n)}}.
%    \]
% 
% 2. Simplify the exponentials:
%    The \(\left(\frac{n}{e}\right)^n\) term dominates the numerator, and dividing by \(\left(\frac{\log(n)}{e}\right)^{\log(n)}\) and \(\left(\frac{n - \log(n)}{e}\right)^{n - \log(n)}\) leads to:
% 
%    \[
%    \left(\frac{n}{n - \log(n)}\right)^{n - \log(n)} \cdot \left(\frac{n}{\log(n)}\right)^{\log(n)}.
%    \]
% 
%    For large \(n\), \(n - \log(n) \sim n\), so:
%    \[
%    \left(\frac{n}{n - \log(n)}\right)^{n - \log(n)} \sim 1.
%    \]
% 
%    The dominant term becomes:
%    \[
%    \left(\frac{n}{\log(n)}\right)^{\log(n)}.
%    \]
% 
% ### Final Asymptotic Estimate
% Thus, the leading-order asymptotic behavior of \(\binom{n}{\log(n)}\) is:
% 
% \[
% \binom{n}{\log(n)} \sim \frac{1}{\sqrt{2 \pi \log(n)}} \cdot \left(\frac{n}{\log(n)}\right)^{\log(n)}.
% \]
% 
% This grows extremely rapidly as \(n\) increases.



\section{Clique is hard for monotone circuits }
The following theorem shows the naive (brute-force) way of computing the CLIQUE function with a monotone circuit shown in Figure \ref{fig:clique-naive}    cannot be improved much.

\begin{figure}
    \centering
    \includegraphics[width=0.3\linewidth]{images/RAZBOROV_Alexander.jpeg}
    \caption{Alexander Razborov. Creator: Kozloff, Robert | Credit: Photo by Robert Kozloff.
Copyright: The University of Chicago}
    \label{fig:enter-label}
\end{figure}


\begin{tcolorbox}[colframe=white, colback=blue!5, boxrule=0mm, sharp corners]
\begin{theorem}[Razborov \cite{Razb85}]\label{thm:razborov} Let $k=\sqrt[4]{n}$. Then, every monotone circuit computing {\rm CLIQUE}$(n, k)$ has size $2^{\Omega(\sqrt[8]{n})}$.
\end{theorem}
\end{tcolorbox}
That is, there exists a constant $c$ such that  for large enough $n \in \mathbb{N}$, if $C_n$ computes CLIQUE$(n,k)$ then $\left|C_n\right| \geq 2^{c \cdot \sqrt[8]{n}}$.


The rest of this chapter aims to prove this theorem. \textit{Our exposition is taken from Papadimitriou's textbook} \cite{Pap94}.


%Recall: a crude circuit is a big OR of cliques, each computed as a big AND.




\section{Proof of monotone circuit lower bounds \Cref{thm:razborov} using the Approximation Method}


\paragraph{Approximation Method Overview}

We first provide an overview of the approach we take to prove \Cref{thm:razborov} which is called \emph{the approximation method}. 
We shall describe a way of approximating any \textbf{monotone} circuit for $\operatorname{CLIQUE}({n}, {k})$ by a crude circuit, namely a big OR of cliques, as follows.
 

\begin{tcolorbox}[colframe=white, colback=blue!5, boxrule=0mm, sharp corners]
\textbf{Approximation Method}:
The upshot of the method is the following: \emph{by  way of contradiction,} consider a purported small monotone circuit computing  $\operatorname{CLIQUE}({n}, {k})$, and show by induction, gradually progressing from the input nodes towards the output node, that the function computed at every gate can be well approximated by a small crude circuit. Then, if the number of nodes in the circuit is small the output gate is also well approximated by a small crude circuit. Now, use an auxiliary argument to show that there is no small crude circuit approximating well  $\operatorname{CLIQUE}({n}, {k})$.
\end{tcolorbox}
% =======
% The upshot is the following: \emph{by way of contradiction,} consider a purported small monotone circuit computing  $\operatorname{CLIQUE}({n}, {k})$, and show by induction, gradually progressing from the input nodes towards the output node, that the function computed at every gate can be approximated by a small crude circuit. Then, the output gate is also approximated by a small crude circuit. Now, use an auxiliary argument to show that there is no small crude circuit approximating $\operatorname{CLIQUE}({n}, {k})$.
% >>>>>>> f39d2195a6351cafba5750ac78532621d361fb0c

More precisely, we have:  
\begin{enumerate}
 
\item  Given a monotone circuit $C$, we shall construct a crude circuit 
$CC(X_1, \ldots, X_m)$ for some $m$ and $|{X}_{i}| \leq l$ (for some $l$, and for $i=1, \ldots, m$ ), that approximates $\operatorname{CLIQUE}({n}, {k})$ with \textbf{precision} that is dependent on the number of gates in $C$.
% =======
% \item  Given a monotone circuit $C$, we shall construct a crude circuit ${CC}({X_1, \ldots, {X_m})}$ for some $m$ and $\left|{X}_{{i}}\right| \leq l$ (for some $l$, and for ${i}=1, \ldots, {m}$ ), that approximates $\operatorname{CLIQUE}({n}, {k})$ with \textbf{precision} that is dependent on the number of gates in $C$.
% >>>>>>> f39d2195a6351cafba5750ac78532621d361fb0c

\item That is, if the number of gates in $C$ is small the precision is  good, namely the crude circuit ${CC}(X_1, \ldots, X_m)$ for $\operatorname{CLIQUE}({n}, {k})$ we end up with makes \textit{few} mistakes on the $\operatorname{CLIQUE}({n}, {k})$ function (a mistake happens when the circuit  answers  "NO" on an input that has a $k$-clique, or "YES" on an input that has no $k$-clique).\label{it:approximation-b}

The \textbf{approximation} (i.e., construction of a crude circuit for CLIQUE(${n},{k})$ given the circuit $C$) will proceed in steps, one step for each gate of the monotone circuit:

\begin{enumerate}
    
\item If $C$ is a monotone circuit computing $\operatorname{CLIQUE}({n}, {k})$ we can \textit{approximate} any gate OR or AND in $C$ with a crude circuit.

\item Each such approximation step introduces rather few errors (false positives and false negatives).
\end{enumerate}



\item We show that every crude circuit ${CC}({X}_1, \ldots, {X_m})$ ($|{X}_i| \leq l$ for some $l$, for all $i=1, \ldots, m$ ), ought to make \textit{exponentially many errors} on the function $\operatorname{CLIQUE}(n, k)$. From \ref{it:approximation-b} above we conclude that there exists no circuit $C$ with a small number of gates. 
\end{enumerate}





\begin{trailer}{Parameters \& notation}

Recall we want to compute CLIQUE$(n, k)$
with $n$ the number of nodes in the graph and $k$ the size of a clique within the graph. 
We set:
$$
k=\sqrt[4]{n}.
$$


$$
\begin{aligned}
& l=\sqrt[8]{n} \\
& p \approx \sqrt[8]{n} \\
& M=(p-1)^l \cdot l! & \approx(\sqrt[8]{n}-1)^{\sqrt[8]{x}} \cdot(\sqrt[8]{n})! \\
& & \leq(\sqrt[4]{n})^{\sqrt[8]{n}}
\end{aligned}
$$


Each (hypothetical) crude-circuit we use in the approximation is:

$$
C C\left(X_1, \ldots, X_m\right)
$$

for $m \leq M$ and $\left|X_i\right| \leq l, \forall i \in[m]$.
\end{trailer}

\newcommand{\cliquenk}{\ensuremath{\operatorname{CLIQUE}(n,k)}}

%___________________________________________________________________
\subsection{The Input Set: Extreme Graphs, False Positive and False Negatives}
%___________________________________________________________________

Here we consider the input graphs we are going to analyse. 
The input set to the \cliquenk\ function are \emph{all possible} binary strings of length $n\choose 2$, namely, all possible (encodings) of undirected graphs with $n$ nodes. This set is easily divided into two groups:

\begin{description}
\item[Accept-instances:] 
$G=(V, E)$ is a graph on $n$ modes that contains a $k$-clique.
\item[Reject-instances:]
$G=(V, E)$ is a graph on $n$ nodes that does not contain a $k$-clique.
\end{description}


 



A crucial point is that \emph{we are going to restrict attention only to a special \textbf{subset} of all possible input graphs}. We call these special input graphs \emph{extreme graphs}. 

\para{Extreme Graphs}
We  restrict attention to only a subsets of accept and reject instances. This is sufficient for the proof (and simplifies it). 
Because extreme graphs are part of the input set, a correct circuit clearly must answer correctly on this subset. So, if we show that there must be mistakes made by small circuits on this subset of input graphs, it is immediate that there is no small monotone circuit that correctly computes \cliquenk.



Thus, our focus is on ``extreme'' cases of inputs:

\begin{description}
\item[\textbf{Positive-inputs}:] 
 $G=(V,E)$ has $n$ nodes and a $k$-clique (i.e., a set of $k$ nodes with all edges between them); while \emph{no} other edge exist in $G$ except for the $k$-clique.

There are $\binom{x}{k}$ positive-inputs, each one is clearly an accept input to \cliquenk.
For simplicity, we shall call these positive inputs \emph{$k$-\textbf{cliques}} (although these are special extreme cases of $k$-cliques, since we assume that all edges outside the clique are absent.) 

\begin{figure}[H]
    \centering
    \includegraphics[width=.5\linewidth]{images/clique1.png}
    \caption{Example of a \emph{positive input}: a graph whose only edges are part of a (single) $k$-clique.}
    \label{fig:enter-label}
\end{figure}


\item[\textbf{Negative-inputs}:] 

$G=\left(V,E\right)$ has $n$ nodes and a $(k-1)$-colouring. I.e., $k-1$ independent sets (each with its own distinct colour), namely sets of nodes, such that in each set there are no edges between nodes. Moreover,  \emph{all} edges between nodes in  different independent sets are present!
For simplicity, we shall call these negative inputs \emph{$(k-1)$-\textbf{colouring}} (although these are special extreme cases of $k-1$-colourable graphs, since we assume that all edges between independent sets are present). 


\begin{figure}[H]
    \centering
    \includegraphics[width=.6\linewidth]{images/clique2.png}
    \caption{Example of a \emph{negative input}: a graph whose all and only edges are between distinct $(k-1)$-independent sets.}
    \label{fig:enter-label}
\end{figure}

\end{description}

\begin{note}\

\begin{enumerate}
\item There are $(k-1)^n$ negative -inputs. (We count twice two identical graphs with colours interchanged.

\item 
 A $(k-1)$-colouring is a negative-input for \cliquenk\ because a $k$-clique cannot be coloured by $k-1$ colours.
\item
 In fact, even a single edge added to a $(k-1)$-colouring will make the graph contain a k-clique!
\end{enumerate}
\end{note}

\para{False Positive and False Negative Inputs}

Let $V$ be a set of $n$ nodes, and  $CC(\mathcal X)$ be a   crude circuit, with  $\mathcal X$ a collection $X_1\dots,X_m\subseteq V$ of subsets of nodes. We say that  a graph $G(V,E)$ (with $n$ nodes) is a \textbf{false positive} if $CC(\mathcal X)(G)=1$ while $G$ is  a $(k-1)$-colouring (and hence, not a $k$-clique). Similarly, a graph $G$ with $n$ nodes $V$ is said to be a \textbf{false negative} if $CC(\mathcal X)(G)=0$ while $G$ \emph{is} a $k$-clique.


% Enable watermark from this point onward
%\SetWatermarkText{DRAFT}
%___________________________________________________________________
%\subsection{Approximating $\lor,\land$ Gates with Crude Circuits %}
%___________________________________________________________________





%\begin{tcolorbox}[colframe=white, colback=red!4, boxrule=0mm, sharp %corners]
%\begin{lemma}[Approximating ]
%\label{lem:}
%
%\end{lemma}
%\end{tcolorbox}


%___________________________________________________________________
\subsection{Concluding the Lower Bound using Structural Induction on the Circuit   }
%___________________________________________________________________



% Recall that our goal is:
% 
% \begin{tcolorbox}[colframe=white, colback=blue!1, boxrule=0mm, sharp corners]
% \textbf{Goal}: Show that every monotone circuit computing $\operatorname{CLIQUE}(n,k)$ has size at least $2^{c \sqrt[8]{n}}$ for some constant $c$ (for sufficiently large $n$).
% \end{tcolorbox}



What does it mean that a crude circuit C(X) \emph{approximates} the monotone circuit C? It means that ``on most'' extreme input graphs $G$, $C(G) = CC(X)(G)$, namely the crude circuit agrees with the actual circuit on most $G$'s. 

The approximation of the  monotone circuit $C$ that computes $\operatorname{CLIQUE}(n, k)$ is constructed  by\emph{ induction on the size of $C$,} i.e., number of $\lor, \wedge$ gates in $C$.


\begin{tcolorbox}[colframe=white, colback=blue!11, boxrule=0mm, sharp corners]
\begin{note} Such an induction is usually called \emph{\textbf{induction on the structure of the circuit} $C$} (or \emph{structural induction}), since we are going to induce on subcircuits of $C$, assuming the induction hypothesis holds for them. Using the structure of the circuit, we shall conclude that the induction hypothesis  holds for the gate that connects those two subcircuits. The base case is showing that the induction statement holds for circuits of size 1 (i.e., singled variable circuits). The induction step is showing that the induction statement holds for $A\lor B$ assuming the induction statement holds for both $A$ and $B$. And similarly for the case of $A\land B$.     
\end{note}
\end{tcolorbox}

 




Now, assume that $C$ is a monotone circuit we wish to build an approximation for. We are going to build the crude circuit for the output gate $C$ gradually, from the input gates of $C$  through the internal gates, up to the output gate, so that the approximator of the output gate will be the approximator of the circuit $C$. The skeleton of this construction is done as follows, following a standard structural induction scheme:

\begin{trailer}
{Approximation of the output gate of $C$ via structural induction}

\textbf{Base step}: input nodes $x_{ij}$. Build an approximator $CC(x_{ij})$ (we shall see this in the next section).


\textbf{Induction step}: 

\case 1 OR gate $g_1\lor g_2$. By induction hypothesis we already built the approximators of $g_1,g_2$, $CC(g_1),CC(g_2)$, respectively. We thus need to construct $CC(g_1\lor g_2)$ from $CC(g_1),CC(g_2)$ (we shall this in the sequel).

\case 2 AND gate $g_1\land g_2$. 
By induction hypothesis we already built the approximators 
of $g_1,g_2$, $CC(g_1),CC(g_2)$, respectively. 
We thus need to construct $CC(g_1\land g_2)$ from 
$CC(g_1),CC(g_2)$ (again, we shall this in the sequel).
\end{trailer}

 We call the two cases of the induction step above \emph{the approximator steps}. Namely, we have an approximator step for an OR gate and an AND gate, resp. 

To prove the lower bound theorem, all we need to know are some properties of the approximator steps. In particular, let the graph $G$ be a false positive of $CC(g_1\lor g_2)$ (i.e., a $(k-1)$-colouring of which $CC(g_1\lor g_2)(G)=1$).
We say the approximator step \emph{introduced $G$ as a new false positive} if $(CC(g_1)\lor CC(g_2))(G)=0$, namely, $G$ is \emph{not} a false positive of $(CC(g_1)\lor CC(g_2))$.
Similarly, let the graph $G$ be a false positive of $CC(g_1\land g_2)$. We say the approximator step \emph{introduced $G$ as a new false positive} if $(CC(g_1)\land CC(g_2))(G)=0$.
 







\begin{lemma}\label{lem:new-false-positives}
Each approximation step introduces at most $M^2 \cdot \frac{(k-1)^n}{2^p}$ false positives.
\end{lemma}

\begin{lemma}\label{lem:new-false-negatives}
Each approximation step introduces at most $M^2 \cdot\binom{n-l-1}{k-l-1}$ false negatives.
\end{lemma}


\bigskip



 a false positive:
$\operatorname{cedpluck}(x \cup y)(G)=0$
$V$-aterosimator
$A(k-1)$-coburing $G=(v, E)$ s.t.

$$
\begin{aligned}
& (\operatorname{cc}(x) \vee \operatorname{cc}(y))(G)=0 \\
& \frac{\operatorname{cc}(p l u c k(x \cup y))(G)}{V \text {-approvinator }}=1
\end{aligned}
$$


1 -apporimator of $\operatorname{CC}(x) \wedge \operatorname{CC}(y)$ introduces
1) a false negative:

A k-clique $G=(v, E)$ s.t: : $(\operatorname{cc}(x) \wedge \operatorname{cc}(y))(G)=1$
2) a false positive: $c c\left(P \mid\right.$ luck $\left.\left\{x_i\left|y_i:\left|x_i \cup y_i\right| \leq l, x_i \in X, y_i \in\right\}\right\}\right)=0$

$$
\left.c c\left(p l u c k\left\{x_i \cup Y_j:\left|x_i \cup y_0\right| \leq l, x_i \in \chi, y_i \in\right\}\right\}\right)=1
$$




Lemma 1: Each approximation step introduces at most $M^2 \frac{(k-1)^n}{2^p}$ false positives.

Pe of F: Case 1: OR-approximator
We start with $\overline{C C}\left(x_1, \ldots, x_m\right)$ and $\operatorname{CC}\left(y_1, \ldots, y_{m_m}\right)$ and consider a false positive introduced by

$$
\operatorname{cc}\left(\text { pluck }\left(X_1, \ldots, X_m, Y_1, \ldots, Y_{m^{\prime}}\right)\right) \text {. }
$$


That is, a $G=(v, E)$ s.t.,

$$
\operatorname{cc}\left(x_1, \ldots, x_m\right)(G)=0, \quad \operatorname{cc}\left(y_1, \ldots, y_m\right)(G)=0
$$

and

$$
\operatorname{cc}\left(\operatorname{pluck}\left(X_1, \ldots, X_m, Y_1, \ldots, Y_{m^{\prime}}\right)\right)(G)=1 .
$$


We consider each plucking involved in (2), and bound from above the number of false positive introduced by this plucking. (Note this is the only reason a false positive can be introduced.)


 - Consider a single plucking : replace sunflower $\left\{z_1, \ldots, z_p\right\}$ by its core $Z$.

By (1): $Y_i^{\prime} s \& X_i^{\prime} s(\&, ' s)$
are all hon-cliques
Thus, by (2)
$Z$ is a clique
and every petal $z_i$
has two nodes w/ the $\frac{\text { same colour! }}{L \operatorname{bg}(1)}$



\begin{figure}[H]
    \centering
    \includegraphics[width=.6\linewidth]{images/clique3.png}
    \caption{Enter Caption}
    \label{fig:enter-label}
\end{figure}


- We count the number of such colourings.
- We do this probabilistically:

Choosing a $(k-1)$-colouring of the nodes randomly and independently, what's the probability every $z_i$ has repeated colours but $z$ does not?
- As before, let $R(X)$ be the probability that $X$ has repeated colours.


$\qquad$ As before, let $R(X)$ be the probability that $X$ has repeated colours.

$$
\operatorname{pr}\left[R\left(z_1\right) \wedge \ldots \wedge R\left(z_p\right) \wedge \neg R(z)\right] \leqslant \operatorname{pr}\left[R\left(z_1\right) \wedge \ldots \wedge R\left(z_p\right) \mid \neg R(z)\right]$$

$$
\begin{aligned}
& =\prod_{i=1}^p \operatorname{Pr}\left[R\left(z_i\right) \mid \neg R(z)\right] \\
& \leqslant \prod_{i=1}^p \operatorname{Pr}\left[R\left(z_i\right)\right]
\leqslant \frac{1}{2^p}
\end{aligned}
$$

$$
\operatorname{Pr}[A \| B]=\operatorname{Pr}[A \mid B] \cdot \operatorname{Pr}[B]
$$


Li's don't have common nodes, except those in $Z$.

We've seen before that

$$
\operatorname{Pr}[R(x)] \leqslant \frac{1}{2}
$$

Probability of repetition of colours is increased if we doit restrict ourselves to colourings w/ no repetitions in $z \subseteq Z_i$.


Finally, since the approximation step entails up to $\frac{2 M}{p-1}$ pluckings (each plucking decreases the number of sets by $\mathrm{p}-1$, and there are no more than 2 M sets when we start), the lemma holds for the OR approximation step: because e

$$
M^2 \cdot \frac{(k-1)^n}{2^p} \geq \frac{2 M}{p-1} \cdot \frac{(k-1)^n}{2^p}
$$


Cont. of proof of Lemma 1

Consider now an AND approximation step of crude circuits $C C(x)$ and $C(y)$. It can be broken down in three phases: First, we form $C C(\{X \cup Y: X \in \chi, Y \in Y\})$; this introduces no false positives, because any graph in which $X U Y$ is a clique must have a clique in both and $Y$, and thus it was accepted by both constituent crude circuits. The second phase omits from the approximator circuit several sets (those of cardinality larger than $\ell$ ), and can therefore introduce no false positives. The third phase entails a sequence of fewer than $\mathrm{M}^2$ plucking, during each of which, by the analysis of the OR case above, at most $2^{-\mathrm{P}}(\mathrm{k}-1)^{\mathrm{n}}$ false positives are introduced. The proof of the lemma is complete: because at total we introduced $\leq M^2 \cdot \frac{(k-1)^n}{2^p}$ false positives




Lemma 2: Each approximation step introduces $\leqslant M^2\binom{n-l-1}{k-l-1}$ false negatives.
PRoOF:
Case $V_{:}$a false negative:
A $k$-clique $G=(v, E)$ st.: $(\operatorname{cc}(x) \vee \operatorname{ccc}(y))(G)=1$ (

$$
\underbrace{\operatorname{colpluck}(x \cup y)(G)}_{V \text {-aproximator }}=0
$$


This is impossible, because plucking only deletes sets and make them smaller; hence if (1) holds then (2) cannot.
Case 1:
A false negative:
A $k$-clique $G=(v, E)$ st: : $(\operatorname{cc}(x) \wedge \operatorname{cc}(y))(G)=1$

$$
\left.c\left(P / \mid u c k\left\{x_i \cup Y_j:\left|x_i \cup Y_i\right| \leq l, x_i \in \chi_{,}, Y_i \in\right\}\right\}\right)=0 \text { (2) }
$$


In the first stop we replace $c a(x) \wedge c(y)$ by $C C(\{X \cup Y: x \in X, y \in Y\})$.
Hence, if $G$ is a $K$-clique and both $X$ and $Y$ are each cliques in $G$, it must be that $X \cup Y$ is also a clique in $G(w h y$ ? ). Thus, no false negatives are introduced in this step.


$\frac{\text { (cont.) }}{\text { We next delete all sets } \overbrace{X_i \cup Y_j}^{\text {denoted }} Z}$ larger than $l$. This introduce several false negatives:
All $k$-cliques $G$ that contain $Z$.
We calculate an upper bound on these false negatives: There are precisely $\binom{n-|z|}{k-|z|}$ k-cliques er that contain $z$ (as part of the clique). Since, $|z|>l$, the upper bound on the false negatives introduced by each deletion is $\binom{n-l-1}{k-l-1}$.

Since there are $\leqslant M^2$ deletions of sets, (because $|\chi|=|y|=M$ ), we get that the number of false negatives introduced by $a_n 1$-approximation step is $\leqslant M^2 \cdot\binom{n-t-1}{k-l-1}$.
